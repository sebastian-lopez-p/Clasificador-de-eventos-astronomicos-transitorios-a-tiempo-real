{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow.tools\n",
    "\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, IntegerType\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "import io\n",
    "import random\n",
    "import avro.schema\n",
    "from avro.io import DatumWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8c8d1",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d71025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To send messages synchronously\n",
    "PRODUCER = KafkaProducer(bootstrap_servers='localhost:9092', value_serializer=lambda v: v)\n",
    "\n",
    "# Kafka topic\n",
    "TOPIC = \"my-topic\"\n",
    "\n",
    "# Path to user.avsc avro schema\n",
    "SCHEMA = {\n",
    "            \"type\": \"record\",\n",
    "            \"name\": \"MultiImageRecord\",\n",
    "            \"fields\": [\n",
    "                {\"name\": \"id\", \"type\": \"int\"},\n",
    "                {\"name\": \"img1\", \"type\": \"bytes\"},\n",
    "                {\"name\": \"img2\", \"type\": \"bytes\"},\n",
    "                {\"name\": \"img3\", \"type\": \"bytes\"}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "for i in range(10):\n",
    "    writer = DatumWriter(SCHEMA)\n",
    "    bytes_writer = io.BytesIO()\n",
    "    encoder = avro.io.BinaryEncoder(bytes_writer)\n",
    "    writer.write({\"name\": \"123\", \"favorite_color\": \"111\", \"favorite_number\": random.randint(0, 10)}, encoder)\n",
    "    raw_bytes = bytes_writer.getvalue()\n",
    "    PRODUCER.send_messages(TOPIC, raw_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3358eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
    "i = 0\n",
    "while i < 100:\n",
    "    producer.send(\"Imagen\", )\n",
    "    time.sleep(1)\n",
    "    i += 1\n",
    "\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05605728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-Saved_model_path es una variable para ingresa la ruta del modelo\n",
    "-filename es la variable que tendra el nombre del archivo con la red ya entrenado\n",
    "\"\"\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Clasificacion_imagenes\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "esquema = StructType() \\\n",
    "    .add(\"id\", IntegerType()) \\\n",
    "    .add(\"value\", IntegerType())\n",
    "\n",
    "spark.sparkContext.addFile(\"saved_model_path\")\n",
    "\n",
    "def predecir(data):\n",
    "    model_file_local = SparkFiles.get(\"filename\")\n",
    "    model = tf.keras.models.load_model(model_file_local, compile=False)\n",
    "    model.predict(data)\n",
    "\n",
    "df_raw = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"Imagen\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "df = df_raw.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col(\"value\"), esquema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "query = df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
